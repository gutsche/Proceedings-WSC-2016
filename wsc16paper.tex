%**************************************************************************
%*
%*  Paper: ``INSTRUCTIONS FOR AUTHORS OF LATEX DOCUMENTS''
%*
%*  Publication: 2016 Winter Simulation Conference Author Kit
%*
%*  Filename: wsc16paper.tex
%*
%*  Date: January 31, 2001   Time:  9:45 PM
%*      BASE of current version: Feb 01, 2010 (primary WSC'10 LaTeX file)
%*
%*  Word Processing System: TeXnicCenter and MiKTeX
%*
%*
%*  All files need the following
\input{wsc16style.tex}     % download from author kit.  Style files for wsc formatting. Don't remove this line - required for generating the final paper!

\documentclass{wscpaperproc}
\usepackage{latexsym}
%\usepackage{caption}
\usepackage{graphicx}
\usepackage{mathptmx}

%
%****************************************************************************
% AUTHOR: You may want to use some of these packages. (Optional)
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{amsthm}
%****************************************************************************



%
%****************************************************************************
% AUTHOR: If you do not wish to use hyperlinks, then just comment
% out the hyperref usepackage commands below.

%% This version of the command is used if you use pdflatex. In this case you
%% cannot use ps or eps files for graphics, but pdf, jpeg, png etc are fine.

\usepackage[pdftex,colorlinks=true,urlcolor=blue,citecolor=black,anchorcolor=black,linkcolor=black]{hyperref}

%% The next versions of the hyperref command are used if you adopt the
%% outdated latex-dvips-ps2pdf route in generating your pdf file. In
%% this case you can use ps or eps files for graphics, but not pdf, jpeg, png etc.
%% However, the final pdf file should embed all fonts required which means that you have to use file
%% formats which can embed fonts. Please note that the final PDF file will not be generated on your computer!
%% If you are using WinEdt or PCTeX, then use the following. If you are using
%% Y&Y TeX then replace "dvips" with "dvipsone"

%%\usepackage[dvips,colorlinks=true,urlcolor=blue,citecolor=black,%
%% anchorcolor=black,linkcolor=black]{hyperref}
%****************************************************************************



		



%
%****************************************************************************
%*
%* AUTHOR: YOUR CALL!  Document-specific macros can come here.
%*
%****************************************************************************

% If you use theoremes
\newtheoremstyle{wsc}% hnamei
{3pt}% hSpace abovei
{3pt}% hSpace belowi
{}% hBody fonti
{}% hIndent amounti1
{\bf}% hTheorem head fontbf
{}% hPunctuation after theorem headi
{.5em}% hSpace after theorem headi2
{}% hTheorem head spec (can be left empty, meaning `normal')i

\theoremstyle{wsc}
\newtheorem{theorem}{Theorem}
\renewcommand{\thetheorem}{ \arabic{theorem}}
\newtheorem{corollary}[theorem]{Corollary}
\renewcommand{\thecorollary}{\arabic{corollary}}
\newtheorem{definition}{Definition}
\renewcommand{\thedefinition}{\arabic{definition}}


%#########################################################
%*
%*  The Document.
%*
\begin{document}

%***************************************************************************
% AUTHOR: AUTHOR NAMES GO HERE
% FORMAT AUTHORS NAMES Like: Author1, Author2 and Author3 (last names)
%
%		You need to change the author listing below!
%               Please list ALL authors using last name only, separate by a comma except
%               for the last author, separate with "and"
%
\WSCpagesetup{Gutsche}

% AUTHOR: Enter the title, all letters in upper case
\title{Dark Matter And Super Symmetry: Exploring And Explaining The Universe With Simulations At The LHC}

% AUTHOR: Enter the authors of the article, see end of the example document for further examples
\author{Oliver Gutsche\\ [12pt]
Scientific Computing Division \\
Fermi National Accelerator Laboratory\\
P.O.Box 500\\
Batavia, IL, 60510, USA\\
}

\maketitle

\section*{ABSTRACT}
The Large Hadron Collider (LHC) at CERN in Geneva, Switzerland, is one of the largest machines on this planet. It is built to smash protons into each other at unprecedented energies to reveal the fundamental constituents of our universe. The 4 detectors at the LHC record multi-Petabyte datasets every year. The scientific analysis of this data requires equally large simulation datasets of the collisions based on the theory of particle physics, the Standard Model. The goal is to verify the validity of the Standard Model or of theories that extend the Model like the concepts of Super Symmetry and an explanation of Dark Matter. I will give an overview of the nature of simulations needed to discover new particles like the Higgs Boson in 2012, and review the different areas where simulations are indispensable: from the actual recording of the collisions to the extraction of scientific results to the conceptual design of improvements to the LHC and its experiments.

\section{INTRODUCTION}
\label{sec:intro}
High Energy Physics (HEP) strives to develop a detailed mathematical understanding of nature at the smallest elementary level. It is based on the interplay between a theoretical framework that describes elementary particles and elementary forces between them, and the experimental detection of particles and measurements of their interactions.

The Standard Model~\shortcite{griffiths2008introduction} contains the current knowledge of particle physics and describes the universe through 12 particles and their anti-particles, and 4 fundamental forces represented by force particles(see Fig.~\ref{fig:sm}). Particles are called fermions and have half-integer spins (one of fundamental properties or quantum numbers of particles) and respect the Pauli exclusion principle (not two particles can be identical in all their quantum numbers). There are 12 fermions, separated into 6 leptons (electron, electron neutrino, muon, muon neutrino, tau, tau neutrino), and 6 quarks (up, down, charm, strange, bottom, top). The hydrogen atom consists of an electron orbiting a proton, which consist of 2 up and 1 down quark.

\begin{figure}[htb]
{
   \centering
   \includegraphics[width=0.30\textwidth]{StandardModel}
   \caption{The Standard Model of particle physics consists of 12 fermions, 6 leptons and 6 quarks, and 5 force particles or bosons.
   \label{fig:sm}}
}
\end{figure}

Force particles are bosons with integer spin and describe the fundamental forces: the electro-magnetic force represented by the photon, the weak force represented by the W and Z bosons, the strong force represented by the gluon, and the recently discovered Higgs boson. Gravitation is not included in the Standard Model because the corresponding graviton has not yet been discovered.

The Standard Model uses the principles of Quantum Field Theory~\shortcite{peskin1995introduction} to mathematically describe particles and their interactions. Today, the Standard Model is very successful in describing matter and their interactions. It took many years and numerous experiments to develop and veify the theory. Although it is self-consistent from the theory point of view, it cannot describe gravitation, account for the accelerating expansion of the universe, and cannot incorporate neutrinos masses. Therefore the field of particle physics is very active in understanding these and other topics and improve and enhance the Standard Model.

\section{SIMULATION}
\label{sec:simulation}

The rules of particle physics are governed by quantum mechanics~\shortcite{feynman1990q}. Therefore description and predictions of particle physics interactions and phenomena have to deal with probablities and sufficiently large statistics to make meaningful statements. Experimentally, only particle interactions that have been observed in sufficient numbers can be meaningfully compared to theoretical predictions. Fortunately, individual particle interactions, may they be produced by particle collisions or otherwise produced, can be treated and detected individually. This makes particle physics a highly parallelizable science.

\subsection{EVENT SIMULATION} 
\label{subsec:eventsimulation}

The empirical calculation of a particle interaction is only possible in approximation and is called event simulation. The problem of describing mathematically a simple collision of two particles producing a different set of two particles at the first and most basic order can be calculated simply by calculating the exchange of a force particle. First the interaction of the two incoming particles producing the force particle is calculated (first vertex), then the decay of the force particle with the outgoing set of two particles (second vertex).

But higher order corrections can play a significant role in calculating this collision. There are two kinds of higher order corrections that are important. 

The first is extending the number of particles and force particles that are produced and exchanged between the first and second vertex. In particle physics speak, the number of vertices is increased and therefore the order of the calculation increases. The more orders are calculated, the closer the approximation of the calculation to the truth. The first order is called the "leading order (LO)" and the next following orders are called "next-to-leader order (NLO)" and "next-to-next-to-leading order (NNLO)". NNLO calculations are currently state-of-the-art in particle physics.

The second kind of higher order correction is harder to approximate. Additional force particles radiated from the incoming or outgoing particles are changing the calculation from above. As there are many possibilities to radiate extra particles with a wide range of possible kinematical parameters (energy, momentum, etc.), a precise or even mathematical approximation is very difficult. Particle physics uses Monte Carlo techniques to approximate these effects. A sufficiently large number of interactions is calculated starting from a random number seed, where every simulated interaction is using a different seed. The random number is used to determine if and how particles are radiated and included in the calculation. Probability density functions are used to constrain the possibilities of radiating particles. These functions are determined by theory confirmed by experiment or by experiment directly.

A sufficiently large statistics of these simulated interactions allows to make statistically significant statements about the interaction of interest, including kinematic distributions of the final state, through averaging the results. Sufficiently large statistics means that the phase space of allowed configurations is sufficiently covered.

\subsection{DETECTOR SIMULATION} 
\label{subsec:detectorsimulation}

To verify or even extend the theory, experiments and the comparison of experimental results with theoretical predictions are needed. The event simulation step described in Sec.~\ref{subsec:eventsimulation} is not directly comparable with measurements of an experimental setup, because only few elementary particles are stable and also detectable in their elementary form.

Of the leptons, only the electron and muon are stable and observable. The tau is decaying into electrons or muons very quickly and the neutrinos are so weakly interacting that neutrino physics is its own branch in particle physics. 

The quarks are not observable individually at all. Governed by the strong force and a concept called confinement~\shortcite{PhysRevD.10.2445}, quarks can only be observed in 2 or 3 quark bound states. 3 quark bound states are called baryons and the most prominent examples are protons and neutrons. 2 quark bound states are called mesons. 

We also cannot control the initial state of a particle interaction to all extend. We can collide for example protons with protons, which means two 3-quark states are colliding, giving multiple possibilities how a certain quark-quark ineraction can be produced. Also these effects can be simulated using Monte Carlo techniques.

The same effect that binds quarks in mesons and baryons also governs the constitution of the final state of an interaction. Because individual quarks cannot exist on their own, quarks that are produced in an interaction hadronize by collecting additional quarks from the vaccum (spontaneous quark anti-quark production following $E=mc~2$) or from neigbouring quarks in the final state of the interaction. Hadronization is described as well with the help of Monte Carlo techniques using underlying models and theories. The same is true for particles that fragment or decay while transversing a detector material.

Detectors are made of matter and detect particles by interacting with them. Dtectors can consists of a gas that is ionized by particles, or a plastic that produces light when a particle transverses the material, or a semi-conductor in which a current can be measured when a particle is passing through. In simulation, we know the final state of an interaction. We encapsulated all theories and models to describe the enegry depositions of particles in material in a single package that is generally used, also outside particle physics, called Geant~\shortcite{Agostinelli2003250,1610988}. Geant simulates the energy deposition of a particle in material, depending on the type of material, the amount of material and the three-dimensional cmoposition of various materials that make up a detector or detector system. 

The last part of the detector simulation step translates the energy depositions of the particles simulated by Geant into electrical signals of the used detectors and detector systems. After this step, a simulated interaction and an experimentally recorded interaction with a detector are equivalent.

\subsection{RECONSTRUCTION}
\label{subsec:reconstruction}

The current understanding of nature in the form of the Standard Model is very advanced. New discoveries or improvements require higher and higher energies in the final state of the produced particle interaction. This requires that particle accelerators are becoming more advanced but also more difficult and costly to build and operate. To maximize the variety of investigations of the produced collisions, a complete capture of the final state of the collisions is required. Sophisticated detector systems that hermetically surround the collision regions are built. Different detector techniques are used to measure different aspects of the final states of the collisions. Charged particle tracks are measured with tracking detectors closests to the interaction region. Particle tracks give momentum and direction of charged particles, if the tracking detectors are situated in a magnetic field. Calorimeters are arranged outside the tracking detectors to measure the energy of particles. Muons are very minimally interacting with material. Special muon detectors outside the calorimeters are built to detect the muons. Fig.~\ref{fig:cmscross} shows the transversal cross section of the CMS detector described in Sec.~\ref{sec:lhc} and how different particles are reconstructed using different detector components.

\begin{figure}[htb]
{
   \centering
   \includegraphics[width=0.80\textwidth]{cms_transversal_drawing}
   \caption{Transversal drawing of the CMS detector showing how electrons, muons, hadrons and photons are reconstructed.
   \label{fig:cmscross}}
}
\end{figure}

Reconstruction software is used to translate the signals and location of the detectors into reconstructed objects that describe particles or jets of particles. At this stage, a comparison to simulation is done and physics results are extracted.

\section{LARGE HADRON COLLIDER AND THE CMS EXPERIMENT}
\label{sec:lhc}

The Large Hadron Collider (LHC)~\shortcite{1748-0221-3-08-S08001} is the current highest energy particle collider in the world. It accelerates protons to 6.5 TeV energy in two circular evacuated beampipes. The beams of protons are brought to collision in 4 points around the almost 17 miles circumference ring (see Fig.~\ref{fig:lhc}). The interaction rate in a single collision point is 40 MHz. Each of the 4 collision points is instrumented with a large particle physics detector system, two multi-purpose detectors and one detector for heavy quark physics and heavy ion physics each. The two multi-purpose detectors have the same physics program but using different detector technology and analysis strategies. This is needed to cross-check results because a second machine of this size would be too expensive to build. In the following, we will concentrate on ond of the two multi-purpose detectors.

\begin{figure}[htb]
{
   \centering
   \includegraphics[width=0.50\textwidth]{lhc}
   \caption{Drawing of the Large Hadron Collider (LHC) at CERN in Geneva, Switzerland.
   \label{fig:lhc}}
}
\end{figure}

The CMS collaboration built, maintains and operates the CMS detector~\shortcite{cms_detector}. CMS stands for "Compact Muon Solenoid", describing the main feature of the compact architecture of the detector system and the emphasis on muon detection. In the innermost layer surrounding the coliision region, a silicon pixel detector is detecting charged particle trajectories. Pixel detectors are like a three-dimensional array of digital camera CMOS chips specifically manufactures to withstand the high data rates and radiation backgrounds from particle collisions of the LHC. Pixel detectors have a very good spatial resultion, needed to detect individual particles which have not yet moved apart significantly while traveling outwards after the collision. The pixel tracker is surrounded by a silicon strip tracker which has a more course resolution but covers a lot more volume. Surrounding the tracking systems is the electro-magnetic calorimeter built from lead-tungsten crystals. The crystals are transparent and produce light proportional to the energy of a passing particle. Completing the calorimetry is the hadronic calorimeter, a sandwich of brass and scintillators to stop hadrons and to measure the penetration depth which is proportional of the energy of the hadrons. The tracking and calorimeter systems are surrounded by a superconducting solenoid producing a magnetic field of 3.8T. With its solenoid size of 6 times 13 meters, it is the largest and most powerful magnet of its kind. Completing the CMS detector is the muon detector system surrounding the magnet instrumenting its return yoke. A drawing of the CMS detector is shown in Fig.~\ref{fig:cms}.

\begin{figure}[htb]
{
   \centering
   \includegraphics[width=0.50\textwidth]{cms}
   \caption{Drawing of CMS detector.
   \label{fig:cms}}
}
\end{figure}


Not all collisions of the 40 MHz collision rate are being recorded and saved for analysis. Most of the collisions can be identified quickly as un-interesting events where the physics is well understood. Also the total data rate and subsequent data volume would be about 1 PB every minute if all of the collisions are recorded. CMS uses a 2 level trigger system to identify collisions for physics analysis. The first level is implemented in custom-made electronics and reduces the data rate to 100 KHz. All detector components have buffers to allow the level 1 decision to be taken within 3 micro-seconds. For selected events, the signals of all detector components are read out and combined into a single event, which is then passed on to the high level trigger. The high level trigger consists of a dedicated compute farm at the detector pit that performs a streamlined version of the full event reconstruction. The high level triger compute farm is dimensioned to sustain an output rate of 1 kHz and an average reconstruction time per event of 200 milliseconds, currently amounting to 22k compute cores. A trigger decision is taken according to the reconstructed information and the events are sent for offline processing, storage and analysis.

Simulations are used in all stages of designing and maintaining the trigger. Starting from the physics program, first and high level trigger selections are designed to maximize interesting events that have the potential to improve the Standard Model or find new physics not yet described by the Standard Model. These selections are then optimized to fit within the latencies of the trigger levels and the timing is checked. Constant feedback from the actual data recording is needed to improve the trigger simulation and the event selection for physics.

\section{PHYSICS WITH THE CMS EXPERIMENT}
\label{sec:physics}

There are two main thrusts in particle physics, improving the Standard Model and its predictive power and finding physics that is not yet described by the Standard Model. The latter category of physics Beyond the Standard Model (BSM) would allow to solve question about the composition of the universe and the existence of the concept of the grand unified theory (GUT). It is known from cosmological observations that the universe consists only to about 4\% of ordinary matter as the Standard Model describes. About 20\% is assumed to be Dark Matter, matter that does not interact electr-magnetically, and about 75\% is assumed to be Dark Energy. Dark Matter particles would be invisible and therefore not detectable in particle physics detectors. But theories predict that at LHC collision energies, Dark Matter particles can be produced under certain circumstances and would manifest themselves in deviations from the Standard Model. The same is true for the concept of Supersymmetry, which doubles the elementary particles to give every particle its super-partner. Supersymmetry would solve the fine-tuning problem in the Standard Model and would also allow for all three forces, electr-magnetic, weak and strong, to unify at high energies and be described by the same simple mathematical construct. This would bring us closer to the Grand Unified Theory of particle physics. Supersymmetric particles would also be a good candidate for Dark Matter.

In all cases the comparison of exeprimental observation to the preductions of the Standard Model are crucial to find deviations. These deviations can then be interpreted in the context of theoretical models like Dark Matter or Supersymmetry and probabilities can be assigned to deviation being compatible with certain theories.

In the case of the Higgs Boson discovery in 2012, theory predicted a number of final states where the new particle was most likely to be discovered. One of them was the 4-lepton final state~\shortcite{cms_higgs_discovery}. Measuring 4-lepton events and indentifying and supressing as much as possible already known interactions predicted by the Standard Model, a peak was discovered that could not be explained by the Standard Model. But adding a Higgs Boson with a mass of about 125 GeV allowed the data to be described by the simulation (see Fig.~\ref{fig:higgs}). The statistical significance of the description exceeded 5 sigma and the signal qualified for the discovery of a Higgs Boson at 125 GeV. Simulations played a crucial role in this discovery.

\begin{figure}[htb]
{
   \centering
   \includegraphics[width=0.50\textwidth]{higgs}
   \caption{Distribution of the four-lepton reconstructed mass for the sum of the 4-electron, 4-muon, and 2-electron 2-muon channels. Points represent the data, shaded histograms represent the background and un-shaded histogram the signal expectations.
   \label{fig:higgs}}
}
\end{figure}

\section{COMPUTING FOR THE CMS EXPERIMENT}
\label{sec:computing}

Producing all the required simulated events is a massive undertaking for the CMS collaboration. Billion's of events need to be simulated and reconstructed to enable all of the currently over 500 publications of CMS. The time to simulate and reconstruct a complete event is a couple of minutes, depending on the run conditions of the LHC. In the current running period, CMS needs over 140k cores to fulfill all simulation and reconstruction needs. CMS uses over 70 computing centers world-wide (see Fig.~\ref{fig:grid}), transparently interconnected through a GRID infrastructure established in the first running period of the LHC~\shortcite{Adelman2013raa}. In the current and next periods, this infrastructure will be enhanced using private and commercial cloud providers and the supercomputers of DOE ASCR and NSF.

\begin{figure}[htb]
{
   \centering
   \includegraphics[width=0.65\textwidth]{grid}
   \includegraphics[width=0.3\textwidth]{grid2}
   \caption{(left) Map of CMS GRID sites (right) CMS GRID infrastructure
   \label{fig:grid}}
}
\end{figure}

\section{The FUTURE: HIGH-LUMINOSITY LHC}
\label{sec:hl-lhc}

The LHC is currently in its 2nd running period. Simulations of impact of the radiation background produced by operating the machine and comparisons to actual degradation of detectors and equipment show that by 2023 many components will reach their end-of-life. Combined with the plan to increase the instantaneous luminosity for the running period 2026-2037 (see Fig.~\ref{fig:hllhc}), a measure of how well the beams are focussed and precicely brought to collision, the LHC and the experiments started upgrade programs for the High-Luminosity LHC (HL-LHC). The higher instantaneous luminosity will allow to increase the physics reach significantly, but also will increase the number of parasitic collisions (PileUp) significantly as well, which increased the demands on the detector systems to realize the increased physics potential. 

\begin{figure}[htb]
{
   \centering
   \includegraphics[width=0.50\textwidth]{hllhc}
   \caption{LHC plan for integrated and instantaneous luminosity over time, covering LHC runs 1-3 and High-Luminosity LHC (HL-LHC.)
   \label{fig:hllhc}}
}
\end{figure}


This results in a large optimization problem, where improvements to the detector systems impact the physics results and the optimization of the physics results require corresponding detector performance. Simulations play a crucial role to optimize detector and physics performance under HL-LHC running conditions. 

\section{Summary}
\label{sec:summary}

Simulations play a crucial role in particle physics. They incorporate the theoretical predictions of the Standard Model and also new theories not yet proven, as well as using Monte Carlo techniques to simulate effects that are not empirically understood. Simulated events are indispensable for the recording of events in developing and optimizing the trigger, in extracting physics results and maybe discoveries, and to plan and optimize updates. All these simulations need a lot of computing resources and it will be crucial for the future success of the LHC and HL-LHC to enable a successful physics harvest.

\section*{ACKNOWLEDGMENTS}
I would like to thank my colleagues of the CMS collaboration to have built, maintain and operate this magnificent detector and computing infrastructure to enable all the extraordinary physics results. I would also like to thank all the international funding agencies that support the CMS collaboration and the LHC, especially the U.S. Department of Energy and the U.S. National Science Foundation.

\appendix


% Please don't exchange the bibliographystyle style
\bibliographystyle{wsc}
% AUTHOR: Include your bib file here
\bibliography{wsc16paper}

\section*{AUTHOR BIOGRAPHIES}

\noindent {\bf Oliver Gutsche} is a staff scientist at the Fermi National Accelerator Laboratory and member of the CMS collaboration of 2,500 physicists, which is operating one of the 4 detectors at the Large Hadron Collider (LHC) at CERN in Geneva, Switzerland. After the Higgs Boson discovery in 2012, his research is focusing on new physics beyond the established theory of particle physics called the Standard Model, especially in the areas of Super Symmetry and Dark Matter. In his role as Assistant Head of the Scientific Computing Division, Dr. Gutsche coordinates the computing needs of the High Energy, Neutrino and Muon Particle Physics experiments at the laboratory. He has intimate knowledge of the large scale computing solutions used for the LHC experiments to analyze multi-Petabyte size datasets on distributed computing infrastructures of many 100,000 cores, having architected many of the used systems and leading the computing operations team of CMS during the first running period of the LHC. His email address is \email{gutsche@fnal.gov}.\\


\end{document}

